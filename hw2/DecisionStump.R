## Decision stump model (1D perceptron) for 1D data classifier
## h(x) = s * sign(x-theta)
## One-dimensional data are generated by
##   (a) Generate x by a uniform distribution in [âˆ’1,1]
##   (b) Generate y by f(x)=sign(x) + noise, the noise flips the result with 20% probability

# Settings
N <- 20          # training set size
errarr <- c()    # E_in of each repetitive training trial
eoutarr <- c()   # E_out of each repetitive training trial
params <- c()    # (s,theta) of each repetitive training trial

# Run the learning for 5000 times
for (k in 1:5000) {
  # Generate the random training data from pattern (a) and (b) (sampling)
  x <- runif(N, -1, 1)
  noise <- numeric(N)
  noise[sample(N, N*.2)] <- noise[sample(N, N*.2)] + 1
  y <- sign(x)
  y[which(noise != 0)] <- y[which(noise != 0)] * -1    # data flip from noise
  
  # Initialize the thresholds for each dichotomy
  theta <- numeric(N)
  datap <- c(-1, sort(x))
  for (i in 1:N) {
    theta[i] <- (datap[i] + datap[i+1])/ 2
  }
  
  err <- 1    # initial error
  for (i in 1:N) {
    ## look up each hypothesis and keep the smallest error
    stmp <- 1
    h <- stmp * sign(x-theta[i])
    errtmp <- mean(as.numeric(h != y))
    if (errtmp < err) {
      err <- errtmp
      s <- stmp
      thres <- theta[i]
    }
    stmp <- -1
    h <- stmp * sign(x-theta[i])
    errtmp <- mean(as.numeric(h != y))
    if (errtmp < err) {
      err <- errtmp
      s <- stmp
      thres <- theta[i]
    }
  }
  errarr <- c(errarr, err)
  params <- rbind(params, c(s,thres))
  eout <- 0.5 + 0.3 *s*(abs(thres) - 1)
  eoutarr <- c(eoutarr, eout)
}
mean(errarr)
mean(eoutarr)

# Plot the final one of the data for vision
plot(which(y==1), x[y==1], pch = 1, col = "blue", ylim = c(-1,1), 
     xlab = "training example m", ylab = "x in [-1,1]")
points(which(y==-1), x[y==-1], pch = 4, col = "red")
